{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rasheed Hameed\n",
    "# Assignment 3 - Automatic Document Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For this problem you will use a different subset of the 20 Newsgroup data set that you used in Assignment 2  (see the description of the full dataset). The subset for this assignment includes 2,500 documents (newsgroup posts), each belonging to one of 5 categories windows (0), crypt (1), christian (2), hockey (3), forsale (4). The documents are represented by 9328 terms (stems). The dictionary (vocabulary) for the data set is given in the file \"terms.txt\" and the full term-by-document matrix is given in \"matrix.txt\" (comma separated values). The actual category labels for the documents are provided in the file \"classes.txt\". Your goal in this assignment is to perform clustering on the documents and compare the clusters to the actual categories. Your tasks in this problem are the following [Note: for the clustering part of this assignment you should use the kMeans module form Ch. 10 of MLA (use the version provided here as it includes some corrections to the book version). You may also use Pandas and other modules from scikit-learn that you may need for preprocessing or evaluation.]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "#to suppresss the orange warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "#Read the data into panda's dataframe\n",
    "classes = np.genfromtxt(\"newsgroups5/classes.txt\",skip_header=1, usecols=(1),dtype=str)\n",
    "print(classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9328, 2500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = pd.read_csv(\"newsgroups5/matrix.txt\", sep=',',header=None)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9328,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        aa\n",
       "1     aargh\n",
       "2     aaron\n",
       "3    aaronc\n",
       "4        ab\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = pd.read_csv(\"newsgroups5/terms.txt\", sep=',', header=None,  dtype='str' )\n",
    "terms=terms.iloc[:,0]\n",
    "print(terms.shape)\n",
    "terms.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a. Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity. This is the distance function you will use to pass to the kMeans function.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "def distCosine(vecA,vecB):\n",
    "    normA = linalg.norm(vecA)\n",
    "    normB = linalg.norm(vecB)\n",
    "    sims = dot(vecA,vecB)/(normA * normB)\n",
    "    dists = 1 - sims\n",
    "    return dists\n",
    "\n",
    "def randCent(dataSet, k):\n",
    "    n = dataSet.shape[1]\n",
    "    centroids = np.zeros((k,n), dtype= float)\n",
    "    for j in range(n): #create random cluster centers\n",
    "        minJ = min(dataSet[:,j])\n",
    "        rangeJ = float(max(dataSet[:,j]) - minJ)\n",
    "        centroids[:,j] = minJ + rangeJ * np.random.rand(k)\n",
    "    return centroids \n",
    "\n",
    "def kMeans(dataSet, k, distMeas=distCosine, createCent=randCent):\n",
    "    m = dataSet.shape[0]\n",
    "    clusterAssment = np.zeros((m,2), dtype=float)#create mat to assign data points \n",
    "                                      #to a centroid, also holds SE of each point\n",
    "    centroids = createCent(dataSet, k)\n",
    "    clusterChanged = True\n",
    "    while clusterChanged:\n",
    "        clusterChanged = False\n",
    "        for i in range(m):#for each data point assign it to the closest centroid\n",
    "            minDist = inf; minIndex = -1\n",
    "            for j in range(k):\n",
    "                distJI = distMeas(centroids[j,:],dataSet[i,:])\n",
    "                if distJI < minDist:\n",
    "                    minDist = distJI; minIndex = j\n",
    "            if clusterAssment[i,0] != minIndex: clusterChanged = True\n",
    "            clusterAssment[i,:] = minIndex,minDist**2\n",
    "        # print centroids\n",
    "        for cent in range(k):#recalculate centroids\n",
    "            ptsInClust = dataSet[nonzero(clusterAssment[:,0]==cent)[0]] #get all the point in this cluster - Note: this was incorrect in the original distribution.\n",
    "            \n",
    "            \n",
    "            if(len(ptsInClust)!=0):\n",
    "                centroids[cent,:] = mean(ptsInClust, axis=0) #assign centroid to mean - Note condition was added 10/28/2013\n",
    "    return centroids, clusterAssment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b. Load the data set [Note: the data matrix provided has terms as rows and documents as columns. Since you will be clustering documents, you'll need to take the transpose of this matrix so that your main data matrix is a document x term matrix. In Numpy, you may use the \".T\" operation to obtain the transpose.] Then, split the data set (the document x term matrix) and set aside 20% for later use (see below). Use the 80% segment for clustering in the next part. The 20% portion must be a random subset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9328, 2500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = matrix\n",
    "DT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 9328)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD = DT.T\n",
    "TD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n"
     ]
    }
   ],
   "source": [
    "NDocs = TD.shape[0]\n",
    "print(NDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9328\n"
     ]
    }
   ],
   "source": [
    "numTerms=TD.shape[1]\n",
    "print(numTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  6 22 ...  3  3  4]]\n"
     ]
    }
   ],
   "source": [
    "# Find doucment frequencies for each term\n",
    "DF = np.array([(TD!=0).sum(0)])\n",
    "print (DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2500. 2500. 2500. ... 2500. 2500. 2500.]\n",
      " [2500. 2500. 2500. ... 2500. 2500. 2500.]\n",
      " [2500. 2500. 2500. ... 2500. 2500. 2500.]\n",
      " ...\n",
      " [2500. 2500. 2500. ... 2500. 2500. 2500.]\n",
      " [2500. 2500. 2500. ... 2500. 2500. 2500.]\n",
      " [2500. 2500. 2500. ... 2500. 2500. 2500.]]\n"
     ]
    }
   ],
   "source": [
    "NMatrix=np.ones(np.shape(TD), dtype=float)*NDocs\n",
    "print (NMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.96578428 8.70274988 6.82828076 ... 9.70274988 9.70274988 9.28771238]\n",
      " [7.96578428 8.70274988 6.82828076 ... 9.70274988 9.70274988 9.28771238]\n",
      " [7.96578428 8.70274988 6.82828076 ... 9.70274988 9.70274988 9.28771238]\n",
      " ...\n",
      " [7.96578428 8.70274988 6.82828076 ... 9.70274988 9.70274988 9.28771238]\n",
      " [7.96578428 8.70274988 6.82828076 ... 9.70274988 9.70274988 9.28771238]\n",
      " [7.96578428 8.70274988 6.82828076 ... 9.70274988 9.70274988 9.28771238]]\n"
     ]
    }
   ],
   "source": [
    "IDF = np.log2(np.divide(NMatrix, DF))\n",
    "print (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the TFxIDF values for each document-term entry\n",
    "TD_tfidf= TD * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test, target_train, target_test = train_test_split(TD_tfidf, classes, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The other numpy conflicts with this numpy below to make the kmeans function work\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9328)\n",
      "(500, 9328)\n",
      "(2000,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c. Perform Kmeans clustering on the training data. Write a function to display the top N terms in each cluster along with the cluster DF values for each term and the size of the cluster. The cluster DF value for a term t in a cluster C is the percentage of docs in cluster C in which term t appears (so, if a cluster has 500 documents, and term \"game\" appears in 100 of those 500 documents, then DF value of \"game\" in that cluster is 0.2 or 20%). Sort the terms for each cluster in decreasing order of the DF percentage. Here is an example of how this output might look like (here the top 10 terms for 3 of the 5 clusters are displayed in decreasing order of cluster DF values, but the mean frequency from the cluster centroid is also shown). [Extra Credit: use your favorite third party tool, ideally with a Python based API, to create a word cloud for each cluster.]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_tfidf = np.array(train)\n",
    "centroids_tfidf, clusters_tfidf = kMeans(TD_tfidf, 5, distCosine, randCent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9328)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = centroids_tfidf.shape[1]\n",
    "centroild2=[]\n",
    "for i in range(i):\n",
    "    centroild2.append(max(centroids_tfidf.T[i]))\n",
    "centroid2=np.array(centroild2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.391884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Centroid\n",
       "0  0.042942\n",
       "1  0.030270\n",
       "2  0.391884\n",
       "3  0.056472\n",
       "4  0.948409"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid=pd.DataFrame(centroid2)\n",
    "centroid.columns=['Centroid']\n",
    "centroid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.780975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.725461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.749828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.813450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster         X\n",
       "0      2.0  0.780975\n",
       "1      0.0  0.901787\n",
       "2      2.0  0.725461\n",
       "3      2.0  0.749828\n",
       "4      3.0  0.813450"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_tfidf\n",
    "\n",
    "clusterdf=pd.DataFrame(clusters_tfidf)\n",
    "clusterdf.columns = ['Cluster', 'X']\n",
    "clusterdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>DF</th>\n",
       "      <th>Centroid</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>%NDocs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.107204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aargh</td>\n",
       "      <td>6</td>\n",
       "      <td>0.030270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaron</td>\n",
       "      <td>22</td>\n",
       "      <td>0.391884</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.235849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaronc</td>\n",
       "      <td>9</td>\n",
       "      <td>0.056472</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.096484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ab</td>\n",
       "      <td>13</td>\n",
       "      <td>0.948409</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.139365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    terms  DF  Centroid  Cluster    %NDocs\n",
       "0      aa  10  0.042942      2.0  0.107204\n",
       "1   aargh   6  0.030270      0.0  0.064322\n",
       "2   aaron  22  0.391884      2.0  0.235849\n",
       "3  aaronc   9  0.056472      2.0  0.096484\n",
       "4      ab  13  0.948409      3.0  0.139365"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mapping terms to documentFrequency\n",
    "termsdf=pd.DataFrame(terms)\n",
    "termsdf.columns = ['terms']\n",
    "DFdf=pd.DataFrame(DF.T)\n",
    "pNDocs=(DFdf/9328)*100\n",
    "DFdf.columns = ['DF']\n",
    "pNDocs.columns = ['%NDocs']\n",
    "\n",
    "#newbie = pd.concat(termsdf,DFdf)\n",
    "\n",
    "RESULTS=pd.concat([termsdf,DFdf,centroid,clusterdf['Cluster'], pNDocs ], axis=1)\n",
    "#newbie.columns=['terms', 'TermFreqPerDoc']\n",
    "RESULTS.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDocsPerCluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLUSTERS</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NDocsPerCluster\n",
       "CLUSTERS                 \n",
       "0.0                   469\n",
       "1.0                     2\n",
       "2.0                   371\n",
       "3.0                  1150\n",
       "4.0                     8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=pd.DataFrame((RESULTS['Cluster'].value_counts() ))\n",
    "counts.columns=['NDocsPerCluster']\n",
    "counts.index.name = 'CLUSTERS'\n",
    "counts.index.astype=int\n",
    "counts=counts.sort_values(by='CLUSTERS')\n",
    "counts\n",
    "#counts.iloc[ 5,: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>DF</th>\n",
       "      <th>Centroid</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>%NDocs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>back</td>\n",
       "      <td>268</td>\n",
       "      <td>1.610812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.873070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>chip</td>\n",
       "      <td>238</td>\n",
       "      <td>1.194889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.551458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>comput</td>\n",
       "      <td>235</td>\n",
       "      <td>1.709234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.519297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>bit</td>\n",
       "      <td>175</td>\n",
       "      <td>92.076030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.876072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>claim</td>\n",
       "      <td>153</td>\n",
       "      <td>0.599292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.640223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>bibl</td>\n",
       "      <td>139</td>\n",
       "      <td>0.790254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.490137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>applic</td>\n",
       "      <td>130</td>\n",
       "      <td>2.132672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.393654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>ago</td>\n",
       "      <td>127</td>\n",
       "      <td>0.317754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.361492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>check</td>\n",
       "      <td>127</td>\n",
       "      <td>0.476651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.361492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>anywai</td>\n",
       "      <td>126</td>\n",
       "      <td>0.277367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.350772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       terms   DF   Centroid  Cluster    %NDocs\n",
       "563     back  268   1.610812      0.0  2.873070\n",
       "1317    chip  238   1.194889      0.0  2.551458\n",
       "1567  comput  235   1.709234      0.0  2.519297\n",
       "791      bit  175  92.076030      0.0  1.876072\n",
       "1384   claim  153   0.599292      0.0  1.640223\n",
       "756     bibl  139   0.790254      0.0  1.490137\n",
       "357   applic  130   2.132672      0.0  1.393654\n",
       "138      ago  127   0.317754      0.0  1.361492\n",
       "1285   check  127   0.476651      0.0  1.361492\n",
       "336   anywai  126   0.277367      0.0  1.350772"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS[RESULTS['Cluster']==0].sort_values(by=['%NDocs','Cluster'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to display the top N terms in each cluster along with the cluster\n",
    "# DF values for each term and the size of the cluster. \n",
    "def TopNTerms(TD_tfidf, terms, DF, k ):\n",
    "    centroids_tfidf, clusters_tfidf = kMeans(TD_tfidf, k, distCosine, randCent)\n",
    "    termsdf=pd.DataFrame(terms)\n",
    "    termsdf.columns = ['terms']\n",
    "    DFdf=pd.DataFrame(DF.T)\n",
    "    pNDocs=(DFdf/9328)*100\n",
    "    DFdf.columns = ['DF']\n",
    "    pNDocs.columns = ['%NDocs']\n",
    "    RESULTS=pd.concat([termsdf,DFdf,centroid,clusterdf['Cluster'], pNDocs ], axis=1)\n",
    "    counts=pd.DataFrame((RESULTS['Cluster'].value_counts() ))\n",
    "    counts.columns=['NDocsPerCluster']\n",
    "    counts.index.name = 'CLUSTERS'\n",
    "    counts=counts.sort_values(by='CLUSTERS')\n",
    "    n = centroids_tfidf.shape[0]\n",
    "    \n",
    "    for i in range(n):\n",
    "       print(\"\\nCluster:\",i)\n",
    "       print(\"\\n\\nCluster size:\", counts.iloc[ i,: ] )\n",
    "       print(RESULTS[RESULTS['Cluster']==i].sort_values(by=['%NDocs','Cluster'], ascending=False ).head(10))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster: 0\n",
      "\n",
      "\n",
      "Cluster size: NDocsPerCluster    469\n",
      "Name: 0.0, dtype: int64\n",
      "       terms   DF   Centroid  Cluster    %NDocs\n",
      "563     back  268   1.610812      0.0  2.873070\n",
      "1317    chip  238   1.194889      0.0  2.551458\n",
      "1567  comput  235   1.709234      0.0  2.519297\n",
      "791      bit  175  92.076030      0.0  1.876072\n",
      "1384   claim  153   0.599292      0.0  1.640223\n",
      "756     bibl  139   0.790254      0.0  1.490137\n",
      "357   applic  130   2.132672      0.0  1.393654\n",
      "138      ago  127   0.317754      0.0  1.361492\n",
      "1285   check  127   0.476651      0.0  1.361492\n",
      "336   anywai  126   0.277367      0.0  1.350772\n",
      "\n",
      "Cluster: 1\n",
      "\n",
      "\n",
      "Cluster size: NDocsPerCluster    2\n",
      "Name: 1.0, dtype: int64\n",
      "          terms  DF  Centroid  Cluster    %NDocs\n",
      "316      annual  16  0.621553      1.0  0.171527\n",
      "1515  commision   3  0.025312      1.0  0.032161\n",
      "\n",
      "Cluster: 2\n",
      "\n",
      "\n",
      "Cluster size: NDocsPerCluster    371\n",
      "Name: 2.0, dtype: int64\n",
      "       terms   DF   Centroid  Cluster    %NDocs\n",
      "417   articl  888   0.895978      2.0  9.519726\n",
      "1084    call  361  22.334859      2.0  3.870069\n",
      "693   believ  326   1.037589      2.0  3.494854\n",
      "676    befor  325   0.665468      2.0  3.484134\n",
      "727     best  259   0.581886      2.0  2.776587\n",
      "1157    case  254   4.948542      2.0  2.722985\n",
      "1498    come  225   0.468226      2.0  2.412093\n",
      "866     book  175   0.599776      2.0  1.876072\n",
      "9        abl  172   0.485768      2.0  1.843911\n",
      "320   answer  168   1.947697      2.0  1.801029\n",
      "\n",
      "Cluster: 3\n",
      "\n",
      "\n",
      "Cluster size: NDocsPerCluster    1150\n",
      "Name: 3.0, dtype: int64\n",
      "          terms   DF  Centroid  Cluster    %NDocs\n",
      "439         ask  338  1.443416      3.0  3.623499\n",
      "1335  christian  251  1.718641      3.0  2.690823\n",
      "1425    clipper  246  1.038466      3.0  2.637221\n",
      "1936        dai  242  1.684425      3.0  2.594340\n",
      "732      better  232  0.527880      3.0  2.487136\n",
      "1977      david  222  1.746648      3.0  2.379931\n",
      "1255      chang  209  0.832108      3.0  2.240566\n",
      "532       avail  200  1.087718      3.0  2.144082\n",
      "1740      cours  195  0.534455      3.0  2.090480\n",
      "1635     consid  193  0.465923      3.0  2.069039\n",
      "\n",
      "Cluster: 4\n",
      "\n",
      "\n",
      "Cluster size: NDocsPerCluster    8\n",
      "Name: 4.0, dtype: int64\n",
      "           terms  DF  Centroid  Cluster    %NDocs\n",
      "843           bo  33  0.504894      4.0  0.353774\n",
      "968       broken  29  0.117412      4.0  0.310892\n",
      "482      atlanta  22  0.128835      4.0  0.235849\n",
      "1076      calcul  21  0.148688      4.0  0.225129\n",
      "1990   dcsedacuk   8  0.050447      4.0  0.085763\n",
      "324   antichrist   4  0.032305      4.0  0.042882\n",
      "434       ashton   4  0.024229      4.0  0.042882\n",
      "1925  cypherpunk   3  0.475828      4.0  0.032161\n"
     ]
    }
   ],
   "source": [
    "TopNTerms(TD_tfidf, terms, DF, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d. Using the cluster assignments from Kmeans clustering, compare your 5 clusters to the 5 pre-assigned classes by computing the Completeness and Homogeneity values.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness Score:          0.7156123899771298\n",
      "Homogeneity:                 0.4445973877194074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "print(\"Completeness Score:         \",completeness_score(target_train,ravel(clusters_tfidf.T[0])))\n",
    "print(\"Homogeneity:                \",homogeneity_score(target_train,ravel(clusters_tfidf.T[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__e. Finally, using your cluster assignments as class labels, categorize each of the documents in the 20% set-aside data into each of the appropriate cluster. Your categorization should be based on Cosine similarity between each test document and cluster centroids. For each test document show the predicted class label as well as Cosine similarity to the corresponding cluster.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20% test data set aside\n",
    "TD_tfidf_test = np.array(test)\n",
    "centroids_tfidf_test, clusters_tfidf_test = kMeans(TD_tfidf_test, 4, distCosine, randCent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 9328) (4, 9328)\n"
     ]
    }
   ],
   "source": [
    "print(TD_tfidf_test.shape,centroids_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21904982,  0.12944547,  0.        , 16.63456858])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids_tfidf_test.T[9327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023683557321118043"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-distCosine(TD_tfidf[0],centroids_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9328)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    287\n",
      "1    212\n",
      "3      1\n",
      "Name: PredictedCluster, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictedCluster</th>\n",
       "      <th>SCluster 1</th>\n",
       "      <th>SCluster 2</th>\n",
       "      <th>SCluster 3</th>\n",
       "      <th>SCluster 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.099109</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.119444</td>\n",
       "      <td>0.194061</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.007016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021460</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.105314</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.070196</td>\n",
       "      <td>0.092188</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PredictedCluster  SCluster 1  SCluster 2  SCluster 3  SCluster 4\n",
       "0                 1    0.099109    0.034571    0.000014    0.001551\n",
       "1                 2    0.119444    0.194061    0.000003    0.007016\n",
       "2                 2    0.021460    0.063866    0.000063    0.001053\n",
       "3                 2    0.105314    0.157973    0.000035    0.002178\n",
       "4                 2    0.070196    0.092188    0.000082    0.002623"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for document in TD_tfidf_test:\n",
    "    dicT = {}\n",
    "    similarity = []\n",
    "    count=1\n",
    "    for centroid in centroids_tfidf_test:\n",
    "\n",
    "        similarity.append(1-distCosine(document, centroid)) \n",
    "        dicT['SCluster '+ str(count)] = 1 - distCosine(document, centroid)\n",
    "        count+=1\n",
    "    dicT['PredictedCluster'] = similarity.index(max(similarity))+1\n",
    "    result.append(dicT)\n",
    "\n",
    "RESULTS = pd.DataFrame(result, index=range(len(TD_tfidf_test)))\n",
    "RESULTS.columns=['PredictedCluster','SCluster 1','SCluster 2', 'SCluster 3','SCluster 4']\n",
    "print(RESULTS['PredictedCluster'].value_counts())\n",
    "RESULTS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
